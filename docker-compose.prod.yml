services:
  db_postgres:
    image: postgres:17
    container_name: db_postgres_prod
    restart: always
    env_file:
      - ./.envs/.env.database.prod
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app_user -d app_db"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init:/docker-entrypoint-initdb.d
    networks: 
      - backend
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 200M
        reservations:
          cpus: '0.1'
          memory: 128M
    command: >
      postgres
      -c max_connections=200
      -c shared_buffers=256MB
      -c effective_cache_size=1GB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=2621kB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  pgbackup:
    image: prodrigestivill/postgres-backup-local:17
    container_name: pgbackup_prod
    restart: always
    env_file:
      - ./.envs/.env.database.prod
    environment:
      - POSTGRES_HOST=db_postgres
      - SCHEDULE=@daily
      - BACKUP_KEEP_DAYS=7
      - BACKUP_KEEP_WEEKS=4
      - BACKUP_KEEP_MONTHS=6
      - HEALTHCHECK_PORT=8080
    volumes:
      - ./backups:/backups
    networks: 
      - backend
    depends_on:
      db_postgres:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
      args:
        - BUILD_DATE=${BUILD_DATE}
        - VERSION=${VERSION}
    container_name: backend_prod
    restart: always
    env_file:
      - ./.envs/.env.backend.prod
      - ./.envs/.env.database.prod
    depends_on:
      db_postgres:
        condition: service_healthy
    networks: 
      - backend
      - frontend
    command: sh -c "alembic upgrade head && uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2 --proxy-headers --forwarded-allow-ips='*'"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.35'
    #       memory: 400M
    #     reservations:
    #       cpus: '0.1'
    #       memory: 200M

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.prod
      args:
        - BUILD_DATE=${BUILD_DATE}
        - VERSION=${VERSION}
    container_name: frontend_prod
    restart: always
    environment:
      - NODE_ENV=production
    depends_on:
      backend:
        condition: service_healthy
    networks: 
      - frontend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  caddy:
    image: caddy:2-alpine
    container_name: caddy_prod
    restart: always
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./caddy/Caddyfile.prod:/etc/caddy/Caddyfile:ro
      - ./caddy/caddy_data:/data
      - ./caddy/caddy_config:/config
      - ./caddy/logs:/var/log/caddy
    depends_on:
      - frontend
      - backend
    networks: 
      - frontend
      - backend
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M
        reservations:
          cpus: '0.05'
          memory: 32M
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  postgres_data:
    driver: local

networks:
  backend:
    driver: bridge
  frontend:
    driver: bridge
